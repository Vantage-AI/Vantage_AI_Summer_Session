{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.envs.registration import register\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Frozen lake explained\n",
    "* Agent has to go from start (S) to the goal (G, a frisbee).\n",
    "* Agent only gets a reward (1) if it makes it all the way to the end. Otherwise (0).\n",
    "* There are 4 actions the agent can perform.\n",
    "* ...but the ice is slippery so sometimes moves in a random direction.\n",
    "\n",
    "SFFF &nbsp;&nbsp;&nbsp; (S: starting point, safe)<br />\n",
    "FHFH &nbsp;&nbsp;&nbsp; (F: frozen surface, safe)<br />\n",
    "FFFH &nbsp;&nbsp;&nbsp; (H: hole, fall to your doom)<br />\n",
    "HFFG &nbsp;&nbsp;&nbsp; (G: goal, where the frisbee is located)<br />\n",
    "\n",
    "* there are only 16 states, so carving up a Q-table is an overseeable effort\n",
    "* 4 actions {0:'left', 1:'down', 2:'right', 3:'up'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create non_slippery environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Create non-slippery frozen lake\n",
    "\n",
    "register(\n",
    "    id='FrozenLakeNotSlippery-v0',\n",
    "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "    kwargs={'map_name' : '4x4', 'is_slippery': False},\n",
    "    max_episode_steps=100,\n",
    "    reward_threshold=0.78, # optimum = .8196\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of a deterministic policy, $\\pi(a|s)$\n",
    "Here we define our own policy: follow the outskirts of the map (top and right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deterministic_policy(state):\n",
    "    \n",
    "    # Go right first\n",
    "    \n",
    "    if (state % 3 != 0) or (state == 0):\n",
    "        action = 2\n",
    "        \n",
    "    # Then go down\n",
    "    else:\n",
    "        action = 1\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frozen_lake_deterministic():\n",
    "    \n",
    "    env = gym.make(\"FrozenLakeNotSlippery-v0\").env\n",
    "\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    reward = 0\n",
    "    \n",
    "    while not done:    \n",
    "        \n",
    "        # Get action from policy given the state we are in\n",
    "        \n",
    "        a = deterministic_policy(s)\n",
    "\n",
    "        # perform action\n",
    "        \n",
    "        s_next, r, done, info = env.step(a)\n",
    "        \n",
    "        # set the next state to the current state\n",
    "        \n",
    "        s = s_next\n",
    "        \n",
    "        # add up the reward\n",
    "        \n",
    "        reward += r\n",
    "\n",
    "        clear_output()\n",
    "        env.render()\n",
    "        time.sleep(1)\n",
    "\n",
    "    if reward == 0:\n",
    "        print(\"\\nWe failed :-(\")\n",
    "    else:\n",
    "        print(\"\\nWe made it! :-D\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFF\n",
      "FHF\u001b[41mH\u001b[0m\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "We failed :-(\n"
     ]
    }
   ],
   "source": [
    "frozen_lake_deterministic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a Q-learning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, learning_rate, epsilon, gamma, n_actions):\n",
    "        \"\"\"\n",
    "        Q-Learning Agent\n",
    "        \"\"\"\n",
    "        \n",
    "        # List possible actions\n",
    "        self.actions = np.arange(n_actions)\n",
    "\n",
    "        # Construct a dictionary that holds Q(s, a)\n",
    "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        \n",
    "        # Learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Epsilon: exploration rate\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # Gamma: reward discount\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def get_qvalue(self, state, action):\n",
    "        \"\"\" Returns Q(state,action) \"\"\"\n",
    "        return self._qvalues[state][action]\n",
    "\n",
    "    def set_qvalue(self,state,action,value):\n",
    "        \"\"\" Sets Q(s, a) [state,action] to the given value \"\"\"\n",
    "        self._qvalues[state][action] = value\n",
    "\n",
    "    #---------------------START OF YOUR CODE---------------------#\n",
    "\n",
    "    def get_value(self, state):\n",
    "        \"\"\"\n",
    "        Compute your agent's estimate of V(s) using current q-values\n",
    "        V(s) = max_over_action Q(state,action) over possible actions.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get Q values\n",
    "        Q_values = np.array([self.get_qvalue(state, a) for a in self.actions])\n",
    "        \n",
    "        # Get V(s) by taking the max of Q_values\n",
    "        value = Q_values[Q_values.argmax()]\n",
    "    \n",
    "        return value\n",
    "\n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        Update the Q value along our experience\n",
    "    \n",
    "        \"\"\"\n",
    "        \n",
    "        gamma = self.gamma\n",
    "        learning_rate = self.learning_rate\n",
    "\n",
    "        Q = self.get_qvalue(state, action)\n",
    "        V = self.get_value(next_state)\n",
    "\n",
    "        if not done:\n",
    "            \n",
    "            Q_hat = Q + learning_rate * (reward + (gamma * V) - Q)\n",
    "            \n",
    "        else:\n",
    "            Q_hat = Q + learning_rate * (reward - Q)\n",
    "            \n",
    "\n",
    "                                                                                \n",
    "        # update Q value in the table\n",
    "        \n",
    "        self.set_qvalue(state, action, Q_hat)\n",
    "    \n",
    "    def get_best_action(self, state):\n",
    "        \"\"\"\n",
    "        Compute the best action to take in a state by picking the action with the highest Q-value. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Get qvalues\n",
    "        qvalues = np.array([self.get_qvalue(state, a) for a in self.actions])\n",
    "\n",
    "        # Get best action\n",
    "        best_action = np.argmax(qvalues)\n",
    "        \n",
    "        return best_action\n",
    "\n",
    "    def get_action(self, state):\n",
    "        \"\"\"\n",
    "        Compute the action to take in the current state, including exploration.  \n",
    "        With probability self.epsilon - we should take a random action.\n",
    "        otherwise - the best action.\n",
    "        \"\"\"\n",
    "\n",
    "        # agent parameters:\n",
    "        epsilon = self.epsilon\n",
    "\n",
    "        # Decide if we pick a random action\n",
    "        if np.random.uniform() < epsilon:\n",
    "            chosen_action = np.random.choice(self.actions)\n",
    "        # Else: get the best action\n",
    "        else:\n",
    "            chosen_action = self.get_best_action(state)\n",
    "\n",
    "        return chosen_action\n",
    "    \n",
    "    def plot(self, episode, agent, mean_rewards, num_episodes):\n",
    "    \n",
    "        clear_output(True)\n",
    "        print(\"--- Epoch: %i ---\"%episode)\n",
    "        print('eps =', agent.epsilon, 'mean reward =', mean_rewards[-1])\n",
    "\n",
    "        # ---> plot reward\n",
    "        size = (10, 5)\n",
    "        fig, ax = pyplot.subplots(figsize=size)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.set_xlabel('epoch', fontsize=12)\n",
    "        ax.set_ylabel('reward', fontsize=12)\n",
    "        plt.plot(mean_rewards)\n",
    "        plt.xlim(0, num_episodes/100)\n",
    "        plt.ylim(0,1)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play the game and update the Q-table as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_episode(env,agent,t_max=10**4, train=False):\n",
    "    \"\"\"\n",
    "    run a full episode along an e-greedy policy\n",
    "    \"\"\"\n",
    "    #  Reset the game\n",
    "    \n",
    "    total_reward = 0\n",
    "    \n",
    "    s = env.reset()\n",
    "    \n",
    "    if not train:\n",
    "        env.render()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    for t in range(t_max): # max steps, otherwise we quit\n",
    "\n",
    "        # First we pick an action in the current state\n",
    "        \n",
    "        if train:\n",
    "            a = agent.get_action(s)\n",
    "        else:\n",
    "            a = agent.get_best_action(s)\n",
    "        \n",
    "        # next, we take a step with this action\n",
    "        \n",
    "        next_s, r, done, _ = env.step(a)\n",
    "\n",
    "        # Finally, given the reward we update the Q-matrix\n",
    "        \n",
    "        if train:\n",
    "            agent.update(s, a, r, next_s, done)\n",
    "        else:\n",
    "            clear_output()\n",
    "            env.render()\n",
    "            time.sleep(1)\n",
    "        s = next_s\n",
    "        total_reward += r\n",
    "        \n",
    "        if done: break\n",
    "    \n",
    "    return total_reward\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def frozen_lake_q(num_episodes, gamma, epsilon, epsilon_decay, learning_rate):\n",
    "    '''\n",
    "    run a number of episodes\n",
    "    '''\n",
    "    \n",
    "    try: \n",
    "        \n",
    "        # create an environment\n",
    "        \n",
    "        env = gym.make(\"FrozenLakeNotSlippery-v0\").env\n",
    "                \n",
    "        n_states = env.observation_space.n\n",
    "        n_actions = env.action_space.n\n",
    "        \n",
    "        # create a Q-table\n",
    "        \n",
    "        Q_matrix = np.zeros((n_states, n_actions))\n",
    "        \n",
    "        rewards = []\n",
    "        episodes = []\n",
    "        \n",
    "        mean_rewards = []\n",
    "\n",
    "        # create an Agent\n",
    "        \n",
    "        agent = Agent(learning_rate=learning_rate, epsilon=epsilon, gamma=gamma, n_actions=n_actions)\n",
    "\n",
    "        for episode in range(num_episodes+1):\n",
    "    \n",
    "            # run an episode\n",
    "            \n",
    "            total_reward = run_episode(env, agent, train=True)\n",
    "            \n",
    "            rewards.append(total_reward)\n",
    "            episodes.append(episode)\n",
    "            \n",
    "            agent.epsilon *= epsilon_decay\n",
    "\n",
    "            # plot results for every set of 100 episodes\n",
    "            \n",
    "            if episode %100 == 0:\n",
    "                # Get mean reward in last 10 sessions\n",
    "                mean_rewards.append(np.mean(rewards))\n",
    "                \n",
    "                agent.plot(episode, agent, mean_rewards, num_episodes)\n",
    "                \n",
    "                for s, a in np.array(np.meshgrid(np.arange(n_states), np.arange(n_actions))).reshape(2, -1).T:\n",
    "                    Q_matrix[s, a] = agent.get_qvalue(s, a)\n",
    "                print(Q_matrix)\n",
    "\n",
    "                time.sleep(0.25)\n",
    "                \n",
    "        return episodes, rewards, agent\n",
    "    \n",
    "    finally:\n",
    "        \n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch: 4000 ---\n",
      "eps = 0.018242480066854295 mean reward = 0.7185703574106473\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.94148015 0.93206532 0.95099005 0.94148015]\n",
      " [0.94148015 0.         0.96059601 0.95099005]\n",
      " [0.95099005 0.970299   0.95099    0.96059601]\n",
      " [0.96059601 0.         0.84448149 0.85125368]\n",
      " [0.88851518 0.75018112 0.         0.94148015]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.9801     0.         0.96059595]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.25616998 0.         0.91928157 0.66636042]\n",
      " [0.59577459 0.98009941 0.87391676 0.        ]\n",
      " [0.9702888  0.99       0.         0.97029872]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.93843361 0.99       0.86488423]\n",
      " [0.98009336 0.98999963 1.         0.98009419]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.99\n",
    "epsilon = 0.999\n",
    "epsilon_decay = 0.999 \n",
    "\n",
    "num_episodes = 4000\n",
    "learning_rate = 1e-1\n",
    "\n",
    "episodes, rewards, agent = frozen_lake_q(num_episodes, gamma, epsilon, epsilon_decay, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play the game along the updated Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "\n",
      "Success! :-D\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLakeNotSlippery-v0\").env\n",
    "\n",
    "reward = run_episode(env, agent, t_max=10**4, train=False)\n",
    "\n",
    "if reward == 1:\n",
    "    print(\"\\nSuccess! :-D\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
